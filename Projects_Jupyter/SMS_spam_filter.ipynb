{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS spam filter using a naive Bayes algorithm\n",
    "\n",
    "The aim of this project is to build a simple Short Message Service (SMS) spam filter, *i.e.*, a function taking a string as input and returning `True` if the message is a spam, and `False` if it is not.\n",
    "We will use a multinomial Bayes algorithm, which is first trained on a corpu of spam and non-spam messages. \n",
    "\n",
    "## A few words on the algorithm\n",
    "\n",
    "Schematically, the algorithm works in the following way. \n",
    "We start from a corpus of many text messages labeled as spam or non-spam. \n",
    "Let $N_s$ be the total number of words in spam messages and $N_{ns}$ the tota number of words in non-spam messages. \n",
    "Let $V$ be the size of the vocabulary, *i.e.*, the total number of different words in the corpus. \n",
    "Let us choose a positive number $\\alpha$, hereafter called the smoothing parameter.\n",
    "For each word $w$, we denote by $N_{w|s}$ the number of times $w$ appears in spam messages and by $N_{w|ns}$ the number of times it appears in non-spam messages. \n",
    "We then define the two weights $p_{w|s}$ and $p_{w|ns}$ by: \n",
    "$$p_{w|s} = \\frac{N_{w|s} + \\alpha}{N_s + \\alpha V}$$\n",
    "and\n",
    "$$p_{w|ns} = \\frac{N_{w|ns} + \\alpha}{N_{ns} + \\alpha V}.$$\n",
    "\n",
    "To build some intuition as to what these weights mean, let us consider two particular cases: \n",
    "* If $\\alpha = 0$, we have $p_{w|s} = \\frac{N_{w|s}}{N_s}$: this is he number of times the word $w$ apears in spam messages divided by the total number of words in spams.\n",
    "Assuming the corpus we are working with is representative, $p_{w|s}$ should thus be close to the probability for a word randomly chosen in a set of spam messages to be equal to $w$. \n",
    "Similarly, $p_{w|ns}$ should be close to the probability for a word randomly chosen in a set of non-spam messages to be equal to $w$. \n",
    "These are the weights one would use in a standard Bayesian analysys.\n",
    "* The problem with these weight is that they vanish if $N_{w|s} = 0$ or $N_{w|ns} = 0$, respectively, *i.e.*, if the word $w$ never appears in spam or in non-spam messages present in the corpus. \n",
    "This is a problem because new messages may contain this word. \n",
    "For instance, if our spam filter were trained with the standard Bayesian weights, any message which contains a word which, in the corpus used for training, is present only in non-spam messages, would be classified as non-spam even if the rest of its content clearly indicates it is a spam.\n",
    "The parameter $\\alpha$ is introduced to circumvent this limitation. \n",
    "Indeed, if $N_{w|s} = 0$, for instance, we get $p_{w|s} = \\frac{\\alpha}{N_s + \\alpha V}$: a typically small, but non-vanishing number. \n",
    "* This parameter also prevents the denominator from being small if the corpus contains too few spam or non-spam messages. \n",
    "For instance, if $N_s \\ll V$, we get $p_{w|s} = \\frac{N_{w|s} + \\alpha}{\\alpha V}$. \n",
    "The larger denominator can prevent the model from being too sensitive to small variations in $N_{w|s}$.\n",
    "\n",
    "Let $m$ be a message (not necessarily in the corpus) made of a succession of $n$ words $w_1$, $w_2$, ..., $w_n$. \n",
    "We define the two weights $p_{m|s}$ and $p_{m|ns}$ by: \n",
    "$$p_{m|s} = \\prod_{i=1}^n p_{w_i|s}$$\n",
    "and \n",
    "$$p_{m|ns} = \\prod_{i=1}^n p_{w_i|ns}.$$\n",
    "(Notice that these definitions are compatible with the above ones if $m$ has exactly one word.)\n",
    "We then estimate the probability $P_{s|m}$ that $m$ is a spam as \n",
    "$$P_{s|m} \\equiv \\frac{p_{m|s} P_s}{p_{m|s} P_s + p_{m|ns} (1-P_s)},$$\n",
    "where $P_s$ is the probability that any message is a spam, and label it as spam if $P_{s|m} > 0.5$.\n",
    "\n",
    "For $\\alpha = 0$ and assuming that each word composing $m$ is in the corpus, $P_{s|m}$ would be the probability that $m$ is a spam given by Bayes' theorem starting from a prior $P_s$ and assuming the words are independent of each others. \n",
    "As mentioned above, the parameter $\\alpha$ is introduced to account for words missing in spams or non-spams in the corpus. \n",
    "In the following, we will first choose the prior $P_s = 0.5$, minimizing the Shannon entropy. \n",
    "It could be tempting to improve the estimate by choosing a different prior, *i.e.*, taking the ratio of spam messages in the corpus. \n",
    "However, this would increase the dependence of the outcome in the representativity of the corpus. \n",
    "For this reason, in this project we will first stick to a prior of $0.5$. \n",
    "We will then see whether changing the prior can improve the results. \n",
    "\n",
    "The corpus we will use is in the text file `SMSSpamCollection`, downloaded from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) on 23 February 2020. \n",
    "It was very slightly modified (I added a quotation mark at the end of line 5082) to ease the import as a Pandas dataframe.\n",
    "It consists of 425 SMS spam messages collected from the Grumbletext website (which seems to be offline at the time of writing (23/02/2020)), 3,375 SMS messages randomly selected from the 10,000 of the NUS SMS Corpus (also offline at the time of writing), 450 SMS ham messages collected from [Caroline Tag's PhD Thesis](https://etheses.bham.ac.uk/id/eprint/253/1/Tagg09PhD.pdf), and 1324 messages from the [SMS Spam Corpus v.0.1 Big](https://www.esp.uem.es/jmgomez/smsspamcorpus/).\n",
    "\n",
    "## Data Exploration\n",
    "\n",
    "Let us first import the Pandas module, which we will use to read and explore the corpus, and the Re module to work with regular expressions.\n",
    "We alsoimport the Pyplot library, which will be used to produce a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the corpus in the `corpus` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two columns separated by a tab, no header\n",
    "# the first column is the label and the second one the message\n",
    "corpus = pd.read_csv('../Data/smsspamcollection/SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ease the analysis, we convert the column `Label` to boolean values, replacing `ham` (denoting a non-spam message) by `False` and `spam` by `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['Label'] = corpus['Label'].replace({'ham':False, 'spam':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print a few informations about the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5574</td>\n",
       "      <td>5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4827</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                     SMS\n",
       "count    5574                    5574\n",
       "unique      2                    5171\n",
       "top     False  Sorry, I'll call later\n",
       "freq     4827                      30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8659849300322928\n"
     ]
    }
   ],
   "source": [
    "summary = corpus.describe()\n",
    "display(summary)\n",
    "nrows = summary.loc['count','Label']\n",
    "print(summary.loc['freq','Label']/nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 5574 rows, as expected. \n",
    "Most of them (4825, *i.e.*, approximately 87%) correpond to non-spam messages.\n",
    "\n",
    "## Training and test sets\n",
    "\n",
    "We now separate the corpus into a training and a test sets. \n",
    "The later will contain approximately 20% of all messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of messages used for the test\n",
    "frac_test = 0.2\n",
    "\n",
    "# randomizing the sample, using a  particular random state to make the results \n",
    "# reproducible (this should not be done in real-world applications!)\n",
    "corpus_rand = corpus.sample(frac=1, random_state=1)\n",
    "\n",
    "# separate it into the training and test dataframes\n",
    "n_messages_training = int((1.-frac_test)*nrows)\n",
    "corpus_training = corpus_rand.iloc[:n_messages_training]\n",
    "corpus_test = corpus_rand.iloc[n_messages_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether they are representative, let us compute the percentage of spam messages in each of these dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of spam messages in the training dataframe: 13.47835837631756%\n",
      "Percentage of spam messages in the test dataframe: 13.094170403587444%\n"
     ]
    }
   ],
   "source": [
    "def percentage_spam(df):\n",
    "    return 100 * df['Label'].sum() / df.shape[0]\n",
    "\n",
    "phrase = 'Percentage of spam messages in the {} dataframe: {}%'\n",
    "print(phrase.format('training', percentage_spam(corpus_training)))\n",
    "print(phrase.format('test', percentage_spam(corpus_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both dataframes have between 13.0% and 13.5% of spam messages, which is close to the percentage of spams in the full corpus. \n",
    "They thus seem to be representative. \n",
    "\n",
    "## Building the corpus of words\n",
    "\n",
    "We now want to extract the words from messages in the traning set. \n",
    "To this end, we first replace all non-alphanumerical characters by spaces and convert all letters to lowercase: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>False</td>\n",
       "      <td>looks like u wil b getting a headstart im leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>False</td>\n",
       "      <td>i noe la    u wana pei bf oso rite    k lor  o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>False</td>\n",
       "      <td>2mro i am not coming to gym machan  goodnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>True</td>\n",
       "      <td>todays vodafone numbers ending with 4882 are s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>False</td>\n",
       "      <td>hi  hope ur day   good  back from walk  table ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>False</td>\n",
       "      <td>how about clothes  jewelry  and trips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry  i ll call later in meeting any thing re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>False</td>\n",
       "      <td>ok lor    or u wan me go look 4 u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>True</td>\n",
       "      <td>u ve been selected to stay in 1 of 250 top bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>False</td>\n",
       "      <td>hello my boytoy     geeee i miss you already a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                                SMS\n",
       "1447  False  looks like u wil b getting a headstart im leav...\n",
       "2032  False  i noe la    u wana pei bf oso rite    k lor  o...\n",
       "4432  False     2mro i am not coming to gym machan  goodnight \n",
       "4888   True  todays vodafone numbers ending with 4882 are s...\n",
       "5276  False  hi  hope ur day   good  back from walk  table ...\n",
       "...     ...                                                ...\n",
       "4255  False             how about clothes  jewelry  and trips \n",
       "1982  False  sorry  i ll call later in meeting any thing re...\n",
       "4755  False                 ok lor    or u wan me go look 4 u \n",
       "4020   True  u ve been selected to stay in 1 of 250 top bri...\n",
       "371   False  hello my boytoy     geeee i miss you already a...\n",
       "\n",
       "[4459 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_training = corpus_training.copy() # to prevent an irrelevant warning\n",
    "corpus_training['SMS'] = corpus_training['SMS'].str.replace('\\W', ' ')\n",
    "corpus_training = corpus_training.copy() # to prevent a false warning\n",
    "corpus_training.loc[:,'SMS'] = corpus_training['SMS'].str.lower()\n",
    "corpus_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the set `vocabulary` containing all the words present in training messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {w for i in range(corpus_training.shape[0]) for w in corpus_training.iloc[i, 1].split()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two dictionaries `count_words_spam` and `count_words_non_spam` count the number of occurrences of each word in the spam and non-spam messages, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words_spam = dict()\n",
    "count_words_non_spam = dict()\n",
    "for i in range(corpus_training.shape[0]):\n",
    "    if corpus_training.iloc[i,0]: # if the message is a spam\n",
    "        for w in corpus_training.iloc[i, 1].split():\n",
    "            if w in count_words_spam:\n",
    "                count_words_spam[w] += 1\n",
    "            else:\n",
    "                count_words_spam[w] = 1\n",
    "    else:\n",
    "        for w in corpus_training.iloc[i, 1].split():\n",
    "            if w in count_words_non_spam:\n",
    "                count_words_non_spam[w] += 1\n",
    "            else:\n",
    "                count_words_non_spam[w] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the total number `Ns` of words in spams, `Nns` of words in non-spam messages, and the size `V` of the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = sum(count_words_spam.values())\n",
    "Nns = sum(count_words_non_spam.values())\n",
    "V = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior probability of a message being a spam, `Ps`, is set to 0.5, and the smoothing parameter `alpha` to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ps = 0.5\n",
    "alpha = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing $p_{w|s}$ and $p_{w|ns}$\n",
    "\n",
    "To make the spam filter more efficient, we pre-compute the conditional probabilities for each word in the vocabulary to appear given that a message is or is not a spam. \n",
    "The results are stored in the dictionaries `p_w_s` and `p_w_ns`. \n",
    "We also define the weight `p_not_in_V_s` and `p_not_in_V_ns` for a word not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_w_s = {w: (count_words_spam[w] + alpha) / (Ns + alpha*V) for w in count_words_spam}\n",
    "p_w_ns = {w: (count_words_non_spam[w] + alpha) / (Nns + alpha*V) for w in count_words_non_spam}\n",
    "\n",
    "p_not_in_V_s = alpha / (Ns + alpha*V)\n",
    "p_not_in_V_ns = alpha / (Nns + alpha*V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `classify` function\n",
    "\n",
    "We define the `classify` function taking a message as a string and returning `True ` if it seems to be a spam and `False` otherwise. \n",
    "If the argument `probability` is set to `True`, it returns the probability that the message is a spam instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message, probability=False, \n",
    "             threshold = 0.5, minval = 10.**(-50)):\n",
    "    '''\n",
    "    Function to estimate if the message seems to be a spam.\n",
    "    If probability is False, it returns True if the message seems to be a spam \n",
    "    and False otherwise. \n",
    "    If probability is True, it returns the estimated probability for the \n",
    "    message to be a spam.\n",
    "    If weights fall below minval, we increase them to avoid reaching 0.\n",
    "    The parameters thresholdis the probability above which we consider the \n",
    "    message is a spam.\n",
    "    '''\n",
    "    \n",
    "    # convert the message to lowercase and replace non-alphanumerical characters by spaces\n",
    "    message = re.sub('\\W', ' ', message).lower()\n",
    "    \n",
    "    # split the message into words\n",
    "    words = message.split()\n",
    "    \n",
    "    # if there is no word, stop the analysis\n",
    "    if not words:\n",
    "        print('I can\\'t find any word in this message')\n",
    "        return None\n",
    "    \n",
    "    # compute p_{m|s} and p_{m|ns}\n",
    "    p_m_s = 1.\n",
    "    p_m_ns = 1.\n",
    "    for w in words:\n",
    "        if w in p_w_s: \n",
    "            p_m_s *= p_w_s[w]\n",
    "        else: \n",
    "            p_m_s *= p_not_in_V_s\n",
    "        if w in p_w_ns: \n",
    "            p_m_ns *= p_w_ns[w]\n",
    "        else: \n",
    "            p_m_ns *= p_not_in_V_ns\n",
    "        while (p_m_s < minval) or (p_m_ns < minval): \n",
    "            p_m_s *= 2\n",
    "            p_m_ns *= 2\n",
    "            \n",
    "    # compute P_{s|m}\n",
    "    P_s_m = p_m_s * Ps / (p_m_s * Ps + p_m_ns * (1.-Ps))\n",
    "    \n",
    "    if probability:\n",
    "        return P_s_m\n",
    "    else:\n",
    "        return P_s_m > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test it on two messages: one which is probably a spam and one which is probably not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "probably_spam = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "probably_non_spam = \"Sounds good, Tom, then see u there\"\n",
    "\n",
    "print(classify(probably_spam))\n",
    "print(classify(probably_non_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the `classify` function\n",
    "\n",
    "Let us now test this function on the test set. \n",
    "We define the accuracy as the fraction of messages correctly labeled. \n",
    "We store the indices of the mislabeled messages in the list `mislabeled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.963\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "mislabeled = []\n",
    "\n",
    "for i in range(corpus_test.shape[0]):\n",
    "    total += 1\n",
    "    if classify(corpus_test.iloc[i,1]) == corpus_test.iloc[i,0]:\n",
    "        correct += 1\n",
    "    else: \n",
    "        mislabeled.append(i)\n",
    "\n",
    "accuracy = correct / total\n",
    "print('The accuracy is: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our spam filter reaches an accuracy of 0.96, which is fairly good.\n",
    "\n",
    "## Changing the prior\n",
    "\n",
    "Let us now see what happens if taking as prior the fraction of spams in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.984\n"
     ]
    }
   ],
   "source": [
    "N_s_training = corpus_training['Label'].sum()\n",
    "N_ns_training = corpus_training.shape[0] - N_s_training\n",
    "Ps = N_s_training / (N_s_training + N_ns_training)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "mislabeled = []\n",
    "\n",
    "for i in range(corpus_test.shape[0]):\n",
    "    total += 1\n",
    "    if classify(corpus_test.iloc[i,1]) == corpus_test.iloc[i,0]:\n",
    "        correct += 1\n",
    "    else: \n",
    "        mislabeled.append(i)\n",
    "\n",
    "accuracy = correct / total\n",
    "print('The accuracy is: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy becomes larger than 0.98, which seems to indicate that it is a more suitable choice of prior. \n",
    "Let us see which messages are still mislabeled: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>True</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>False</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>False</td>\n",
       "      <td>26th OF JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>False</td>\n",
       "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>False</td>\n",
       "      <td>Miss call miss call khelate kintu opponenter m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>False</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>False</td>\n",
       "      <td>CHEERS U TEX MECAUSE U WEREBORED! YEAH OKDEN H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>False</td>\n",
       "      <td>Madam,regret disturbance.might receive a refer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>True</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>True</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>False</td>\n",
       "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>False</td>\n",
       "      <td>Garbage bags, eggs, jam, bread, hannaford whea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>False</td>\n",
       "      <td>Gibbs unsold.mike hussey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>False</td>\n",
       "      <td>Except theres a chick with huge boobs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>True</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>False</td>\n",
       "      <td>CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>True</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>False</td>\n",
       "      <td>Raviyog Peripherals bhayandar east</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                                SMS\n",
       "3460   True  Not heard from U4 a while. Call me now am here...\n",
       "3890  False                  Unlimited texts. Limited minutes.\n",
       "991   False                                       26th OF JULY\n",
       "989   False  Yun ah.the ubi one say if ü wan call by tomorr...\n",
       "4488  False  Miss call miss call khelate kintu opponenter m...\n",
       "326   False                   No calls..messages..missed calls\n",
       "3149  False  CHEERS U TEX MECAUSE U WEREBORED! YEAH OKDEN H...\n",
       "2419  False  Madam,regret disturbance.might receive a refer...\n",
       "3864   True  Oh my god! I've found your number again! I'm s...\n",
       "4676   True  Hi babe its Chloe, how r u? I was smashed on s...\n",
       "3094  False  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323\n",
       "5336  False  Garbage bags, eggs, jam, bread, hannaford whea...\n",
       "886   False                           Gibbs unsold.mike hussey\n",
       "5455  False             Except theres a chick with huge boobs.\n",
       "1638   True  0A$NETWORKS allow companies to bill for SMS, s...\n",
       "2171  False  CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER ...\n",
       "869    True  Hello. We need some posh birds and chaps to us...\n",
       "3270  False                 Raviyog Peripherals bhayandar east"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test.iloc[mislabeled]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of them are genuine messages mislabeled as spams.\n",
    "\n",
    "## Taking new messages into account\n",
    "\n",
    "One of the features of machine learning compared with classical statistical anaysis is the possibility to continually learn by including new information. \n",
    "To take advantage of this, we define the function `update` taking a message as a string, a label `True` or `False`, and updating the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(message, is_spam, change_prior=False):\n",
    "    '''\n",
    "    This function updates the spam filter given a new message and a label \n",
    "    is_spam equal to true if it is a spam and False otherwise. \n",
    "    If change_prior is true, the prior Ps is updated\n",
    "    \n",
    "    message: string\n",
    "    is_spam: bool\n",
    "    change_prior: bool (optional)\n",
    "    '''\n",
    "    \n",
    "    # define variables as global to be able to modify them \n",
    "    global N_s_training, N_ns_training, Ps, p_w_s, p_w_ns, p_not_in_V_s, \\\n",
    "           p_not_in_V_ns, count_words_spam, count_words_non_spam, Ns, Nns, \\\n",
    "           vocabulary, V\n",
    "    \n",
    "    # add new words to the vocabulary\n",
    "    \n",
    "    if is_spam:\n",
    "        N_s_training += 1\n",
    "        for word in re.sub('\\W', ' ', message).lower().split():\n",
    "            vocabulary.add(word)\n",
    "            if w in count_words_spam:\n",
    "                count_words_spam[w] += 1\n",
    "            else:\n",
    "                count_words_spam[w] = 1\n",
    "        V = len(vocabulary)\n",
    "        Ns = sum(count_words_spam[w] for w in count_words_spam)\n",
    "    else:    \n",
    "        N_ns_training += 1\n",
    "        for word in re.sub('\\W', ' ', message).lower().split():\n",
    "            vocabulary.add(word)\n",
    "            if w in count_words_non_spam:\n",
    "                count_words_non_spam[w] += 1\n",
    "            else:\n",
    "                count_words_non_spam[w] = 1\n",
    "        V = len(vocabulary)\n",
    "        Nns = sum(count_words_non_spam[w] for w in count_words_non_spam)\n",
    "        \n",
    "    if change_prior:\n",
    "        Ps = N_s_training / (N_s_training + N_ns_training)\n",
    "    \n",
    "    p_w_s = {w: (count_words_spam[w] + alpha) / (Ns + alpha*V) for w in count_words_spam}\n",
    "    p_w_ns = {w: (count_words_non_spam[w] + alpha) / (Nns + alpha*V) for w in count_words_non_spam}\n",
    "\n",
    "    p_not_in_V_s = alpha / (Ns + alpha*V)\n",
    "    p_not_in_V_ns = alpha / (Nns + alpha*V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the value of $\\alpha$\n",
    "\n",
    "Let us now see how changing $\\alpha$ affects the results. \n",
    "To this end, we define the function `update_alpha_and_train` wich changes the value of $\\alpha$, re-trains the model, and prints its acuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_and_train(new_alpha):\n",
    "    '''\n",
    "    update the value fof alpha, re-train the model, and return its accuracy\n",
    "    '''\n",
    "    global alpha, p_w_s, p_w_ns, p_not_in_V_s, p_not_in_V_ns\n",
    "    \n",
    "    # update alpha\n",
    "    alpha = new_alpha\n",
    "\n",
    "    # re-compute the weights\n",
    "    p_w_s = {w: (count_words_spam[w] + alpha) / (Ns + alpha*V) for w in count_words_spam}\n",
    "    p_w_ns = {w: (count_words_non_spam[w] + alpha) / (Nns + alpha*V) for w in count_words_non_spam}\n",
    "\n",
    "    p_not_in_V_s = alpha / (Ns + alpha*V)\n",
    "    p_not_in_V_ns = alpha / (Nns + alpha*V)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    mislabeled = []\n",
    "\n",
    "    for i in range(corpus_test.shape[0]):\n",
    "        total += 1\n",
    "        if classify(corpus_test.iloc[i,1]) == corpus_test.iloc[i,0]:\n",
    "            correct += 1\n",
    "        else: \n",
    "            mislabeled.append(i)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try with $\\alpha$ ranging from 0.0001 to 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_min = 0.0001\n",
    "alpha_max = 10.\n",
    "n_values = 100\n",
    "\n",
    "alpha_values = [alpha_min*(alpha_max/alpha_min)**(i/(n_values+1)) for i in range(n_values)]\n",
    "acc_values = list(map(update_alpha_and_train, alpha_values))\n",
    "\n",
    "plt.semilogx(alpha_values, acc_values)\n",
    "plt.xlim(alpha_min, alpha_max)\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting accuracy seems to be virtually independent of $\\alpha$, although choosing $\\alpha = 0.01$ seems to give the best results, with an accuracy of $0.99$.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this project, we built a classifier to determine whether an SMS is a spam or not, using a naive Bayes algorithm. \n",
    "We found that best results are achived when whoosing as prior the fraction of spam messages in the corpus and a value of the smoothing parameter close to 0.01. \n",
    "The resulting accuracy was 99%. \n",
    "\n",
    "This indcates that, if this model were to be used in real-world applications, a good prior to start with would be the fraction of SMS received by a user that are spam. \n",
    "The optimum value of $\\alpha$ will likely depend on the size ot the corpus (we expect it to decrease as the size of the corpus increses). \n",
    "From our results, taking $\\alpha = 0.01$ should be a good starting value if the available corpus has a few thousand messages. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
